
# Aufarbeitung von Fragebogendaten {#rohdaten}

Unser Ziel ist die Auswertung echter Daten von
Persönlichkeits-Fragebögen wie den BIG-5 und dem Narcissistic
Personality Inventory. Leider liegen in echten Daten die Werte oftmals
nicht in der Form vor, die wir brauchen. Daten enthalten in Rohform
unter Umständen gar nicht die Informationen, die wir benötigen, oder
haben fehlende Werte. Deswegen werden wir uns als nächstes mit den
folgenden Themen beschäftigen:

1. Umkodierung von Antworten
2. Invertierung von Antworten
3. Umgang mit fehlenden Werten

## Umkodierung von Antworten {#umkodierung}

Eine wichtige Voraussetzung für eine psychometrische Analyse war im
Beispiel in Kapitel 4 bereits gegeben: Jeder Wert kodierte genau die
Information, die wir brauchten -- nämlich ob Schüler/innen eine Aufgabe
korrekt gelöst hatten oder nicht (dargestellt durch `1` und `0`). In
echten Daten muss die relevante Information jedoch häufig erst noch aus
den dokumentierten Werten „abgeleitet“ werden. Die Antwort der
Schüler/innen im Test könnte beispielsweise ein Kreuz in einem
Multiple-Choice-Item sein:

> Aus wie vielen Bundesländern besteht die Bundesrepublik Deutschland?

> (1) 14
> (2) 16
> (3) 19
> (4) 21

Ob ein Kreuz bei (1), (2), (3) oder (4) gesetzt wird, ist für die
Auswertung nicht von Belang. Relevant ist, ob die Frage richtig
beantwortet wurde -- wir benötigen also die folgende Umkodierung der
Daten:

- `1` $\to$ `0`
- `2` $\to$ `1`
- `3` $\to$ `0`
- `4` $\to$ `0`

In psychometrischem Jargon: Für diese Aufgabe ist der Wert `2` der
*Schlüssel* (engl.: *key*). Ein Schlüssel kodiert den Eingabewert der
richtigen Antwort.[^schluessel] Wir lernen jetzt, wie wir solche
Umkodierungen in `R` umsetzen. Die Stärke einer Programmiersprache wie
`R`: Wenn wir einmal gelernt haben, wie wir für eine
Item-Schlüssel-Kombination Daten als richtig und falsch umkodieren,
können wir mit nur ein wenig mehr Aufwand diesen Prozess für beliebig
viele Items wiederholen. Das *Narcissistic Personality Inventory* etwa
hat 40 Items und wir haben keine Lust, 40 Mal eine Umkodierung
„händisch“ neu durchzuführen.

[^schluessel]: Im Allgemeinen muss ein Schlüssel nicht Korrektheit
anzeigen, sondern kann auch Merkmalsausprägung in einem
Persönlichkeitsinventar kodieren. Wir werden das im Narcissistic
Personality Inventory kennenlernen.

### Die Funktion `ifelse`

Mit der Funktion `ifelse` lassen sich Transformationen, die anhand
eines Schlüssels Korrektheit kodieren, bequem durchführen. Das folgende
Beispiel basiert auf dem obigen Multiple-Choice-Item:

```{r}

# Hypothetische Antworten auf das Bundesland Multiple-Choice-Item:
bundesland_answers <- c(1, 2, 1, 3, 2, 4, 2)
bundesland_key     <- 2

bundesland_score   <- ifelse(test = bundesland_answers == bundesland_key,
                             yes = 1, no = 0)
bundesland_score

```

Was ist hier passiert? Ich habe im Vektor `bundesland_answers`
hypothetische Antworten generiert; die Variable `bundesland_key` enthält
den Schlüssel, d.h. die korrekte Antwort. Mithilfe der Funktion `ifelse`
gleiche ich die Antworten mit dem Schlüssel ab.  `ifelse` nimmt drei
Argumente entgegen. Diese heißen `test`, `yes`, und `no`:[^positionname]

[^positionname]: Wie wir gesehen haben, können wir Argumente in
Funktionen per Name und per Position ansteuern.

- `test`: Vergleicht jede Antwort mit dem Schlüssel, hier:
  `bundesland_answers == bundesland_key`. Ergebnis dieses Vergleichs ist
  der folgende logische Vektor (im Allgemeinen kann `test` einen
  beliebigen logischen Vektor als Argument annehmen):


```{r, echo = FALSE}
bundesland_answers == bundesland_key
```

- `yes`: Der Wert, der angenommen werden soll für Elemente, für die der
  `test` `TRUE` ergab (hier: `1`)
- `no`: Der Wert, der angenommen werden soll für Elemente, für die der
  `test` `FALSE` ergab (hier: `0`). Praktisch: ich muss nicht angeben,
  welche falschen Werte alle möglich sind; es reicht aus, den richtigen
  Wert anzugeben, alle anderen sind automatisch falsch

Nach der Umkodierung können wir beispielsweise die Schwierigkeit des
Bundesland-Items mit der `mean` Funktion berechnen:

```{r}
mean(bundesland_score)
```

In diesem Fall hätten `r round(mean(bundesland_score)*100)`% der
Testteilnehmer das Bundesland-Item korrekt beantwortet. Diese
Information konnten wir aus den ursprünglichen Antwortkategorien 1, 2, 3
und 4 nicht herleiten.

Die Funktion `ifelse` ist sehr nützlich, mit der wir Antworten
umkodieren können. Später lernen wir, wie wir mithilfe von `ifelse`
ganze Tests und nicht nur einzelne Items bepunkten können.  Bevor wir
das jedoch effizient machen können, werden wir im nächsten Kapitel noch
ein paar Grundlagen zur Programmierung mit `R` lernen.

## Invertierung von Antworten

Eine mögliche Umkodierung von Antworten ist das Abgleichen mit einem
Schlüssel, etwa zur Feststellung der Korrektheit von Antworten. Eine
weitere häufig auftretende Variante ist die *Invertierung* von
Antworten. Betrachten wir folgende zwei Items, die in einer Big-5
Kurzskala den Aspekt Extraversion messen:

> 1. Ich bin eher zurückhaltend, reserviert.
> 2. Ich gehe aus mir heraus, bin gesellig.

Beide Items werden auf einer Likertskala mit fünf Abstufungen gemessen,
das heißt es werden Punktzahlen von 1 bis 5 vergeben. Das Problem ist,
dass in Item 1 ein hoher Punktwert für wenig Extraversion steht, in Item
2 ein hoher Punktwert hingegen für eine hohe Ausprägung in
Extraversion. Generell wollen wir einen *Summenwert* berechnen, also
einen Wert, der die Extraversion eines jeden Testteilnehmers kodiert --
und zwar über beide Items hinweg. Im vorliegenden Fall macht es aber
keinen Sinn, die Punktzahlen beider Items zu addieren. Die höchste
Ausprägung in Extraversion würde sich dann ergeben, wenn ein Item
extravertiert beantwortet wird, aber das andere introvertiert. Damit die
Punktzahlen in beiden Items „in dieselbe Richtung“ zu verstehen sind,
wollen wir die Antworten auf Item 1 *invertieren*, sodass auch hier eine
hohe Punktzahl für eine hohe Merkmalsausprägung in Extraversion
steht. Das heißt, wir wollen die folgende Abbildung durchführen:

- `1` $\to$ `5`
- `2` $\to$ `4`
- `3` $\to$ `3`
- `4` $\to$ `2`
- `5` $\to$ `1`

Wir könnten dies mit mehrfacher Anwendung von `ifelse` hinbekommen,
was jedoch mühsam wäre. Es gibt eine mathematische Umformung, welche wir
auch mit nur wenig Code umsetzen können:

> Invertierter Wert = Ursprungswert * (-1) + Höchster Skalenwert + 1

Diese funktioniert, wenn unsere Punktzahlen zwischen 1 und dem
höchstmöglichen Skalenwert liegen. Probieren wir es mit ein paar
hypothetischen Antworten aus:

```{r}
big5 <- data.frame(item1 = c(2, 3, 2, 1, 4, 2, 1, 5),
                   item2 = c(5, 3, 3, 4, 3, 5, 3, 2))

## Betrachte den data.frame:
big5
```

Wir können uns mit der `cor` Funktion die Korrelation zwischen den
zwei Items ausgeben lassen:

```{r}
round(cor(big5), 2)
```

Ich habe die Antwortwerte absichtlich so gewählt, dass sich hier ein
typisches Muster ergibt: Antworten auf unterschiedlich gepolte Items --
die zur selbem Skala gehören -- korrelieren typischerweise negativ
miteinander. Das heißt: Hohe Antwortwerte im einen Item gehen
tendenziell mit niedrigen Werten im anderen Item einher -- wenn die
unterschiedlich gepolten Items dasselbe Konstrukt erfassen. Durch die
Invertierung erhalten wir Daten, die positiv miteinander
korrelieren. Folgender Code führt die Invertierung durch:

```{r}
# 5 ist der höchst-mögliche Skalenwert
big5$item1_inv <- big5$item1 * (-1) + 6
```

Schauen wir uns die Daten an, um zu prüfen, ob die Transformation
funktioniert hat:

```{r}
big5[, c("item1", "item1_inv")]
```

Das hat geklappt! Schauen wir uns nun auch noch einmal die
Inter-Itemkorrelationen an:

```{r}
round(cor(big5), 2)
```

Wie wir sehen, korrelieren die Spalten `item2` und `item1_inv` genau wie
`item2` und `item1` -- nur mit positivem Vorzeichen. Ebenfalls
interessant: `item1` und `item1_inv` korrelieren perfekt negativ -- und
das ist genau das, was wir mit der Invertierung erreichen wollten: Einen
Punktwert errechnen, der genau in die entgegengesetzte Richtung zu
interpretieren ist wie der ursprüngliche Wert.

## Umgang mit fehlenden Werten

> Real data have missing values. Missing values are an integral part of
> the R language.  Many functions have arguments that control how
> missing values are to be handled. -- Patrick Burns[^zitatmissing]

[^zitatmissing]:
http://www.burns-stat.com/documents/tutorials/why-use-the-r-language/

Wir lernen nun den rudimentären Umgang mit fehlenden Werten in `R`
kennen. Dabei könnte man vermutlich beliebig sophistiziert vorgehen,
jedoch werden wir nur einen basalen und wichtigen Spezialfall
kennenlernen:

1. Wir wandeln alle Werte in `NA` um, die als fehlend zu klassifizieren
   sind
2. Danach schließen wir alle Fälle mit fehlenden Werten aus

Für dieses Beispiel laden wir Daten des Narcissistic Personality
Inventory [NPI; @raskin1988] ein. Die Daten von mehr als 11,000
Bearbeitungen des NPI sind erfreulicherweise über das „Open Source
Psychometrics Project“ unter
[https://openpsychometrics.org/_rawdata](https://openpsychometrics.org/_rawdata)
abrufbar. Wenn wir die Daten heruntergeladen haben und die Datei
„data.csv“ in unserem RStudio-Projektordner liegt (siehe
[Anhang](#datenEinlesen)), können wir den Datensatz wie folgt einlesen:

```{r}
## Lese Daten ein
npi <- read.csv("data.csv")
```

Wie folgt verschaffen wir uns einen Überblick über die Daten:

```{r}
nrow(npi) # Wie viele Fälle
ncol(npi) # Wie viele Spalten
names(npi) # wie heißen die Messvariablen
head(npi, n = 3) # Wie sehen die Daten aus
```

Wir bemerken, dass keine Variable als "Fallnummer" fungiert.  Generell
ist es **immer** wichtig, dass jeder Datensatz durch eine eindeutige
Fallnummer zu identifizieren ist. Da eine solche in den eingelesenen
Daten jedoch nicht enthalten ist, fügen wir selber eine Fallnummer
hinzu:

```{r}
npi$casenum <- 1:nrow(npi)
```

Eine weitere nützliche Funktion zum Betrachten von `data.frames` ist die
Funktion `summary`, die uns einen schnellen Überblick über die Werte in
allen Spalten des `data.frames` bietet:

```R
summary(npi)
```

Die Funktion `summary` ergibt für jede Spalte eine Tabelle. Wegen der
Länge des Outputs von `summary(npi)` ist nicht der gesamte Output im
Skript abgebildet.[^selbstarbeiten] Für die Variable `score` erhalten wir
folgende Informationen zum Narzissmus-Gesamtscore:

[^selbstarbeiten]: Ich schlage vor, die Funktion selber auf den Datensatz
aufzurufen, um die Zusammenfassung für alle Spalten zu betrachten.

```{r, echo = FALSE}
kable(summary(npi)[,1], col.names = "score")
```

&nbsp;

**Identifikation von fehlenden Werten im NPI Datensatz**

Das NPI besteht aus 40 Items. Aus dem *Codebuch* des NPI
Datensatzes[^codebuch] wissen wir, dass Antworten auf die NPI Items
die Werte 1 und 2 annehmen können.  Die Antwort auf jedes Item des NPI
besteht aus einer „forced choice“ zwischen zwei Aussagen; eine davon
steht für Narzissmus. Item 1 besteht beispielsweise aus den folgenden
beiden Aussagen:

[^codebuch]: Dieses wird gemeinsam mit den Daten des „Open Source
Psychometrics Project“
[https://openpsychometrics.org/_rawdata](https://openpsychometrics.org/_rawdata)
runtergeladen.

> 1. I have a natural talent for influencing people.
> 2. I am not good at influencing people.

Die Wahl von Aussage 1 wird mit 1 kodiert, die Wahl von Aussage 2
mit 2. Nachgeschaltet wird folgende Umkodierung vorgenommen, die die
Item-Scores berechnet: Wird die „narzisstische Aussage“ ausgewählt (hier
Aussage 1: „I have a natural talent for influencing people.“), wird das
Item mit 1 bepunktet. Wird die Aussage gewählt, die nicht für Narzissmus
steht (hier Aussage 2: „I am not good at influencing people.“), wird
eine 0 vergeben. Wie wir zu Beginn des Abschnitts gelernt haben, könnten
wir Item 1 deswegen wie folgt bepunkten:

```R
npi$Q1_score <- ifelse(npi$Q1 == 1, 1, 0)
```

**Aber Vorsicht: so würden wir einen Fehler machen**! Die Spalte
`npi$Q1` enthält nicht nur die Werte 1 und 2, sondern auch 0-Werte, wie
wir mit dem Befehl `table(npi$Q1)` prüfen können:[^plausicheck]

[^plausicheck]: **Merke**: Es ist wichtig, sich einen Überblick über
Daten zu verschaffen und unplausible und fehlende Werte zu
identifizieren. Die Funktionen `summary` und `table` sind dabei
hilfreich.

```{r}
table(npi$Q1)
```

Wie wir sehen, wurden die Antwortkategorien 0, 1 und 2 vergeben. Es
kommt sogar `r table(npi$Q1)[1]` Mal die Antwortkategorie 0 vor --
**obwohl Antworten nur die Werte 1 und 2 annehmen dürfen**. Wie kommt
das?  Die Antwort ist: Bei der Bearbeitung des NPI-Fragebogens -- welche
im Rahmen einer Online-Studie stattfand -- konnten Teilnehmer/innen
Items unbeantwortet lassen. Fehlende Werte in den Antworten wurden mit
einer 0 kodiert.[^schlechtekodierung]

[^schlechtekodierung]: Ich halte dies für kein gutes Vorgehen. Der Wert
0 ist nicht ausreichend unterschiedlich von anderen „legalen Werten“ in
den anderen Spalten. Der Gesamt-Testscore (`npi$score`) kann
beispielsweise wirklich den Wert 0 annehmen, wenn Teilnehmer/innen kein
einziges Mal der narzisstischen Aussage zugestimmt haben -- und dies kam
tatsächlich 73 Mal vor. Der Wert `-99` wäre beispielsweise ein besserer
Wert gewesen, um fehlende Werte zu kodieren.

&nbsp;

**Ausschluss von Fällen mit fehlenden Werten**

&nbsp;

Wir wollen als nächstes alle Fälle ausschließen, bei denen mindestens
ein fehlender Wert in den Antworten auf die 40 NPI Items vorliegt,
d.h. für mindestens eine der Spalten `npi$Q1`, ..., `npi$Q40` der Wert 0
ist. Erst danach können wir die Itemscores berechnen.

Zu diesem Zweck speichern wir zunächst die Antworten auf die 40 Items
und die Fallnummer in einem neuen `data.frame` ab. Anhand dieses
`data.frames` werden wir die Fallausschlüsse durchführen:

```{r}
item_responses <- npi[, c("casenum", paste0("Q", 1:40))]
```

Wir können jetzt 0-Werte in `NA` umkodieren, indem wir ein Vorgehen
verwenden, das wir in [Kapitel 2](#vektorAendern) für Vektoren
kennengelernt haben. Dieses Vorgehen funktioniert bei `data.frames`
tatsächlich genauso:[^fortgeschritten]

[^fortgeschritten]: Der Befehl sieht recht harmlos aus, aber tatsächlich
steckt hier etwas mehr drin als wir bislang behandelt haben. Wir nehmen
zunächst einmal einfach hin, dass man die Umkodierung von fehlenden
Werten in `data.frames` genauso durchführen kann wie in
Vektoren. Beachtet, dass hier ein Zugriff auf `data.frames` mit eckigen
Klammern stattfindet (siehe [Kapitel 3.5](#fortgeschritten); tatsächlich
ist dieser Zugriff aber sogar noch etwas spezieller als der in Kapitel
3.5 beschriebene -- hier ist das Objekt in den eckigen Klammern eine
*Matrix* vom Typ „logical“).

```{r}
item_responses[item_responses == 0] <- NA
```

Für einzelne Spalten kann man mithilfe der Funktion `is.na`
überprüfen, ob diese fehlende Werte enthalten. `is.na` ergibt einen
logischen Vektor, der kodiert, ob jedes Element des übergebenen Vektors
-- also etwa eine Spalte, die wir mit der `$`-Notation ausgelesen haben
-- `NA` ist. Mit diesem Wissen können wir etwa für einzelne Items
überprüfen, wie viele Personen keine Antwort angegeben haben:

```{r}
sum(is.na(item_responses$Q1))
sum(is.na(item_responses$Q40))
```

**Wichtig**: Man **muss** `is.na` verwenden, um zu prüfen, ob Werte `NA`
sind; Folgendes geht schief:[^naisweird]

[^naisweird]: Ein logischer Vergleich mit `NA` ergibt immer `NA`, da
beim fehlenden Wert keine Aussage darüber gemacht werden kann, ob er
einem anderen Wert entspricht. Man kennt ihn ja nicht. Auch der Befehl
`TRUE & NA` ergibt `NA`.

```{r}
## Nutze head, um nicht alle 11,000 Vergleiche auszugeben
head(item_responses$Q1 == NA)
```

Um insgesamt einen Überblick über die Verteilung der fehlenden Fälle zu
erhalten, bietet sich eine erneute Anwendung der Funktion `summary`
an. Diese gibt nämlich direkt für jede Spalte eines `data.frames` die
Zahl der fehlenden Fälle an. Folgende Information gibt es zum ersten
Item:

&nbsp;

```{r, echo = FALSE}
kable(summary(item_responses)[,2], col.names = "Q1")
```

&nbsp;

Jetzt, da wir fehlende Antworten per `NA` als fehlend gekennzeichnet
haben, gibt es verschiedene Möglichkeiten, die zugehörigen Fälle
auszuschließen. Eine Möglichkeit wäre eine Aneinanderreihung von vielen
ODER-Verknüpfungen, an die wir eine Auswahl mit `subset` oder der
`[·,·]`-Notation anschließen. Dies könnte wie folgt funktionieren:

```R

## Identifiziere Fälle, die in irgendeinem Item einen
## fehlenden Wert haben (hier nur exemplarisch, kein
## legaler R-Code, da Items 4 bis 39 nicht ausgeschrieben
## sind):
irgendwo_na <- is.na(item_responses$Q1) |
    is.na(item_responses$Q2) |
    is.na(item_responses$Q3) |
    ... |
    is.na(item_responses$Q40)

## Negation durchführen, um die Fälle zu erwischen, die
## *keinen* fehlenden Wert enthalten
nirgendwo_na <- !irgendwo_na

## Wähle diese Fälle aus:
item_responses <- item_responses[, nirgendwo_na]

```

Durch die Verknüpfung der ODER-Operatoren werden alle Fälle
identifiziert, die mindestens eine fehlende Antwort enthalten. Diese
Aneinanderreihung ist jedoch mühselig und fehleranfällig. Diese Arbeit
wollen wir uns nicht machen.

Eine weitere Methode, fehlende Werte zu identifizieren nutzt aus, dass
die Funktion `rowSums`[^schauzurueck] `NA` ausgibt, wenn mindestens ein
Wert aus einer Zeile `NA` enthält -- zumindest wenn wir nicht das
optionale Argument `na.rm` auf `TRUE` setzen. Dies ist analog zu der
Funktion `sum`, die für einen einzelnen Vektor eine Summe bestimmt. Die
Funktion `sum` gibt ebenfalls `NA` aus, wenn mindestens ein Element des
übergebenen Vektors `NA` ist und `na.rm` nicht auf `TRUE` gesetzt
wurde. Die Funktion `rowSums` erweitert also auch im Hinblick auf den
Umgang mit fehlenden Werten das Verhalten von `sum` auf alle Zeilen
eines `data.frames`. Aus diesem Grund funktioniert das hier:

[^schauzurueck]: siehe das [ausgedehnte Beispiel zum
Einstieg](#kap4einstieg)

```R
## Identifiziere Fälle, die in irgendeinem Item einen
## fehlenden Wert haben:
irgendwo_na <- is.na(rowSums(item_responses))
```

Am bequemsten ist es jedoch, wenn wir die Funktion `na.omit` nutzen, die
uns einfach so alle Fälle ausschließt, die fehlende Werte enthalten:

```{r}
item_responses <- na.omit(item_responses)
```

Die Funktion `na.omit` gibt einen `data.frame` aus, der keine der Zeilen
enthält, in denen mindestens ein `NA`-Wert vorlag. So müssen wir nicht
selber die Zeilen identifizieren, die fehlende Werte enthalten.

Vergleichen wir nun den ursprünglichen `data.frame` `npi` mit der
„bereinigten“ Tabelle:[^plausicheckagain]

[^plausicheckagain]: Es ist immer wichtig, solche
Plausibilitätsüberprüfungen durchzuführen, nachdem man Daten geändert
hat.

```{r}
nrow(npi)
nrow(item_responses)
```

Wie wir sehen, haben wir `r nrow(npi) - nrow(item_responses)` Fälle
wegen fehlender Werte ausgeschlossen. Etwas unschön ist, dass in unseren
bereinigten Daten einige Variablen -- wie das Geschlecht und das Alter
-- fehlen. Das liegt daran, dass wir für den Ausschluss von Fällen nur
die Item-Antworten berücksichtigt haben, die wir zuvor im `data.frame`
`item_responses` abgespeichert haben. Vergleichen wir:

```{r}
names(npi)
names(item_responses)
```

Um einen `data.frame` zu erhalten, in dem alle Informationen zu den
vollständigen Fällen enthalten sind, machen wir uns zunutze, dass die
relevanten Informationen noch im Urspungs-`data.frame` `npi`
abgespeichert sind. Wie folgt können wir mit der Funktion `merge` die
ursprüngliche Tabelle `npi` mit der um fehlende Fälle bereinigten
Tabelle `item_responses` zusammenführen.

```{r}
npi_clean <- merge(npi, item_responses)
```

Wir erhalten in der Variablen `npi_clean` einen Datensatz, der nur Fälle
mit vollständigen Antworten enthält -- und für diese Fälle auch alle
Werte abspeichert. Prüfe:

```{r}
nrow(npi_clean)
names(npi_clean)
```

Die Funktionsweise der Funktion `merge` soll hier nicht tiefergehend
betrachtet werden. Es reicht zu wissen, dass sie Fälle aus zwei
`data.frames` anhand ihrer Werte zuordnet.[^fallnummeristwichtig] Dabei
werden Fälle weggelassen, die keinen „Partner“ haben -- also hier Fälle,
zu denen nur in einer Tabelle eine Fallnummer vorliegt. Die Fälle ohne
Partner sind hierbei genau die Fälle, die aus `npi_clean` wegen
fehlender Werte ausgeschlossen wurden.

[^fallnummeristwichtig]: Hierfür war es wichtig, dass wir vorher eine eindeutige
Fallnummer vergeben haben. Anhand dieser Fallnummer können wir nun die
Fälle beider Tabellen eindeutig einander zuordnen.

Die Anwendung der Funktion `merge` hat die Reihenfolge unserer Daten
durcheinander gebracht. Es ist nicht so wichtig, warum das so ist, aber
wir wollen diesen Nebeneffekt wieder rückgängig machen. Deswegen nutzen
wir die Funktion `arrange` aus dem Paket `dplyr`, um die Daten wieder
anhand der Fallnummer zu sortieren:

```{r}
library("dplyr") # falls noch nicht geladen
npi_clean <- arrange(npi_clean, casenum)
```

Voilá -- `npi_clean` ist der Datensatz, mit dem wir nun psychometrische
Berechnungen durchführen können.[^nochmehrplausichecks] Dabei ist unser
nächstes Ziel für alle 40 Items eine dichotome Bepunktung durchzuführen.
Wir wissen bereits, wie wir das machen könnten, nämlich indem wir mit
`ifelse` die Antworten auf jedes Item mit dem Schlüssel abgleichen. Der
Schlüssel für den das NPI kodiert für jedes der 40 Items den Wert, der
für Narzissmus steht. Dies wäre wie folgt möglich:

[^nochmehrplausichecks]: Es ist zu bemerken, dass wir noch nicht alle
Variablen auf ihre Plausibilität überprüft haben. Die Spalte `age`
enthält ebenfalls noch fehlende sowie auch gänzlich unplausible Werte
(etwa 366 oder 509). Auch die Spalte `elapse`, die die Bearbeitungszeit
abspeichert, enthält teilweise unplausible Werte; das Maximum der
gespeicherten Bearbeitungszeit liegt bei über 40 Jahren. Doch darauf
soll erst einmal nicht unser Augenmerk liegen.

```R
# Hier kein legaler R-Code, nur exemplarisch:
npi_key <- c(1, 1, ..., 2) # 40 Schlüsselemente

npi$Q1_score <- ifelse(npi$Q1 == npi_key[1], 1, 0)
npi$Q2_score <- ifelse(npi$Q2 == npi_key[2], 1, 0)

...
...
...

npi$Q40_score <- ifelse(npi$Q40 == npi_key[40], 1, 0)
```

Da wir nicht denselben Code -- mit leichten Abwandlungen -- 40 Mal
wiederholen wollen, werden wir in Kapitel 7 lernen, diese Umkodierungen
effizient durchzuführen. 
