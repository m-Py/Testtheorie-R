
# Aufarbeitung von Fragebogendaten {#rohdaten}

Unser Ziel ist die Auswertung echter Daten aus Fragebögen wie den BIG-5
und dem Narcissistic Personality Inventory. Allerdings liegen echte
Daten oftmals nicht in der Form vor, die wir benötigen. Echte Daten
haben fehlende Werte, und meistens müssen wichtige Informationen erst
aus den bestehenden Variablen abgeleitet werden. Aus diesem Grund
beschäftigen wir uns im vorliegenden Kapitel mit den folgenden Themen:

1. Umkodierung von Antworten
2. Invertierung von Antworten
3. Umgang mit fehlenden Werten

## Umkodierung von Antworten {#umkodierung}

Eine wichtige Voraussetzung für eine psychometrische Analyse war im
Beispiel in Kapitel 4 bereits gegeben: Jeder Wert kodierte genau die
Information, die wir brauchten -- nämlich ob Schüler/innen eine Aufgabe
korrekt gelöst hatten oder nicht (dargestellt durch `1` und `0`).  Bei
echten Datenerhebungen wird im Normalfall aber nicht direkt Korrektheit
kodiert, sondern diese wird aus der eigentlichen Antwort abgeleitet. Die
Antwort könnte beispielsweise ein Kreuz in einem Multiple-Choice-Item
sein:

> Aus wie vielen Bundesländern besteht die Bundesrepublik Deutschland?

> (1) 14
> (2) 16
> (3) 19
> (4) 21

Bei der Dateneingabe des Tests kann zwischen 1 und 4 kodiert werden,
welche der vier Antwortoptionen ausgewählt wurde. Ob ein Kreuz bei (1),
(2), (3) oder (4) gesetzt wird, ist für die Datenauswertung aber nicht
unbedingt von Belang. Es ist vor allem relevant, ob die Frage richtig
beantwortet wurde -- wir benötigen also die folgende Umkodierung der
Daten:

- `1` $\to$ `0`
- `2` $\to$ `1`
- `3` $\to$ `0`
- `4` $\to$ `0`

In psychometrischem Jargon: Der Wert `2` ist der *Schlüssel* (engl.:
*key*) dieser Aufgabe. Ein Schlüssel kodiert den Eingabewert der
richtigen Antwort.[^schluessel] Wir lernen jetzt, wie wir solche
Umkodierungen in `R` umsetzen. Die Stärke einer Programmiersprache wie
`R`: Wenn wir einmal gelernt haben, wie wir für eine
Item-Schlüssel-Kombination Daten als richtig und falsch umkodieren,
können wir mit nur ein wenig mehr Aufwand diesen Prozess für beliebig
viele Items wiederholen. Das *Narcissistic Personality Inventory* etwa
hat 40 Items und wir haben keine Lust, 40 Mal eine Umkodierung
händisch neu durchzuführen.

[^schluessel]: Im Allgemeinen muss ein Schlüssel nicht Korrektheit
anzeigen, sondern kann auch Merkmalsausprägung in einem
Persönlichkeitsinventar kodieren. Wir werden das im Narcissistic
Personality Inventory kennenlernen.

### Die Funktion `ifelse`

Mit der Funktion `ifelse` lassen sich Transformationen, die anhand
eines Schlüssels Korrektheit kodieren, bequem durchführen. Das folgende
Beispiel basiert auf dem obigen Multiple-Choice-Item:

```{r}

# Hypothetische Antworten auf das Bundesland Multiple-Choice-Item:
bundesland_answers <- c(1, 2, 1, 3, 2, 4, 2)
bundesland_key     <- 2
bundesland_score   <- ifelse(test = bundesland_answers == bundesland_key,
                             yes = 1, no = 0)
bundesland_score

```

Was ist hier passiert? Ich habe im Vektor `bundesland_answers`
hypothetische Antworten generiert; die Variable `bundesland_key` enthält
den Schlüssel, d.h. die korrekte Antwort. Mithilfe der Funktion `ifelse`
gleiche ich die Antworten mit dem Schlüssel ab.  `ifelse` nimmt drei
Argumente entgegen. Diese heißen `test`, `yes`, und `no`:

- `test`: Ein logischer Vektor -- hier der Vergleich jeder 
  Antwort mit dem Schlüssel
- `yes`: Die Ausgabe an den Positionen, an denen der `test` `TRUE` ergibt
- `no`: Die Ausgabe an den Positionen, an denen der `test` `FALSE` ergibt

In diesem Fall wird dem Argument `test` der folgende logische Vektor
übergeben:

```{r}
bundesland_answers == bundesland_key
```

An allen Positionen, an denen dieser Vergleich `TRUE` ergibt, gibt die
Funktion `ifelse` den Wert 1 aus -- also den Wert, der dem Argument
`yes` übergeben wurde. An allen anderen Positionen steht 0 -- also der
Wert, der dem Argument `no` übergeben wurde. Praktisch: Ich muss nicht
angeben, welche falschen Werte alle möglich sind; es reicht aus, im
`test` mit dem richtigen Wert zu vergleichen. Alle anderen Werten werden
dann automatisch als falsch interpretiert.

Nach der Umkodierung können wir mit der Funktion `mean` die
Schwierigkeit des Items berechnen:

```{r}
mean(bundesland_score)
```

In diesem Fall hätten `r round(mean(bundesland_score)*100)`% der
Testteilnehmer das Bundesland-Item korrekt beantwortet. Diese
Information konnten wir aus den ursprünglichen Antwortkategorien 1, 2, 3
und 4 nicht herleiten. Auch um Item-Trennschärfen, Cronbachs Alpha oder
andere Kennwerte zu bestimmen, ist die Umkodierung eine notwendige
Voraussetzung.

## Invertierung von Antworten

Eine mögliche Umkodierung von Antworten ist das Abgleichen mit einem
Schlüssel, etwa zur Feststellung der Korrektheit von Antworten. Eine
weitere häufig auftretende Variante ist die *Invertierung* von
Antworten. Betrachten wir folgende zwei Items, die in einer Big-5
Kurzskala den Aspekt Extraversion messen:

> 1. Ich bin eher zurückhaltend, reserviert.
> 2. Ich gehe aus mir heraus, bin gesellig.

Beide Items werden auf einer Likertskala mit fünf Abstufungen gemessen,
das heißt es werden Punktzahlen von 1 bis 5 vergeben. Das Problem ist,
dass in Item 1 ein hoher Punktwert für wenig Extraversion steht, in Item
2 ein hoher Punktwert hingegen für eine hohe Ausprägung in
Extraversion. Generell wollen wir einen *Summenwert* berechnen, also
einen Wert, der die Extraversion eines jeden Testteilnehmers kodiert --
und zwar über beide Items hinweg. Im vorliegenden Fall macht es aber
keinen Sinn, die Punktzahlen beider Items zu addieren. Die höchste
Ausprägung in Extraversion würde sich dann ergeben, wenn ein Item
extravertiert beantwortet wird, aber das andere introvertiert. Damit die
Punktzahlen in beiden Items „in dieselbe Richtung“ zu verstehen sind,
wollen wir die Antworten auf Item 1 *invertieren*, sodass auch hier eine
hohe Punktzahl für eine hohe Merkmalsausprägung in Extraversion
steht. Das heißt, wir wollen die folgende Abbildung durchführen:

- `1` $\to$ `5`
- `2` $\to$ `4`
- `3` $\to$ `3`
- `4` $\to$ `2`
- `5` $\to$ `1`

Wir könnten dies mit mehrfacher Anwendung von `ifelse` hinbekommen,
was jedoch mühsam wäre. Es gibt eine mathematische Umformung, welche wir
auch mit nur wenig Code umsetzen können:

> Invertierter Wert = Ursprungswert * (-1) + Höchster Skalenwert + 1

Diese funktioniert, wenn unsere Punktzahlen zwischen 1 und dem
höchstmöglichen Skalenwert liegen. Probieren wir es mit ein paar
hypothetischen Antworten aus:

```{r}
big5 <- data.frame(item1 = c(2, 3, 2, 1, 4, 2, 1, 5),
                   item2 = c(5, 3, 3, 4, 3, 5, 3, 2))

## Betrachte den data.frame:
big5
```

Wir können uns mit der `cor` Funktion die Korrelation zwischen den
zwei Items ausgeben lassen:

```{r}
round(cor(big5), 2)
```

Ich habe die Antwortwerte absichtlich so gewählt, dass sich hier ein
typisches Muster ergibt: Antworten auf unterschiedlich gepolte Items --
die zur selbem Skala gehören -- korrelieren typischerweise negativ
miteinander. Das heißt: Hohe Antwortwerte im einen Item gehen
tendenziell mit niedrigen Werten im anderen Item einher -- wenn die
unterschiedlich gepolten Items dasselbe Konstrukt erfassen. Durch die
Invertierung erhalten wir Daten, die positiv miteinander
korrelieren. Folgender Code führt die Invertierung durch:

```{r}
# 5 ist der höchst-mögliche Skalenwert
big5$item1_inv <- big5$item1 * (-1) + 6
```

Schauen wir uns die Daten an, um zu prüfen, ob die Transformation
funktioniert hat:

```{r}
big5[, c("item1", "item1_inv")]
```

Das hat geklappt! Schauen wir uns nun auch noch einmal die
Inter-Itemkorrelationen an:

```{r}
round(cor(big5), 2)
```

Wie wir sehen, korrelieren die Spalten `item2` und `item1_inv` genau wie
`item2` und `item1` -- nur mit positivem Vorzeichen. Ebenfalls
interessant: `item1` und `item1_inv` korrelieren perfekt negativ -- und
das ist genau das, was wir mit der Invertierung erreichen wollten: Einen
Punktwert errechnen, der genau in die entgegengesetzte Richtung zu
interpretieren ist wie der ursprüngliche Wert.

## Umgang mit fehlenden Werten

> Real data have missing values. Missing values are an integral part of
> the R language.  Many functions have arguments that control how
> missing values are to be handled. -- Patrick Burns[^zitatmissing]

[^zitatmissing]:
http://www.burns-stat.com/documents/tutorials/why-use-the-r-language/

Wir lernen nun den rudimentären Umgang mit fehlenden Werten in `R`
kennen. Dabei könnte man vermutlich beliebig sophistiziert vorgehen,
jedoch werden wir nur einen basalen und wichtigen Spezialfall
kennenlernen:

1. Wir wandeln alle Werte in `NA` um, die als fehlend zu klassifizieren
   sind
2. Danach schließen wir alle Fälle mit fehlenden Werten aus

Für dieses Beispiel laden wir Daten des Narcissistic Personality
Inventory [NPI; @raskin1988] ein. Die Daten von mehr als 11,000
Bearbeitungen des NPI sind erfreulicherweise über das „Open Source
Psychometrics Project“ unter
[https://openpsychometrics.org/_rawdata](https://openpsychometrics.org/_rawdata)
abrufbar. Wenn wir die Daten heruntergeladen haben und die Datei
„data.csv“ in unserem RStudio-Projektordner liegt (siehe
[Anhang](#datenEinlesen)), können wir den Datensatz wie folgt einlesen:

```{r}
## Lese Daten ein
npi <- read.csv("data.csv")
```

Wie folgt verschaffen wir uns einen Überblick über die Daten:

```{r}
nrow(npi) # Wie viele Fälle
ncol(npi) # Wie viele Spalten
head(npi, n = 3) # Wie sehen die Daten aus
```

Wir bemerken, dass keine Variable als "Fallnummer" fungiert. Generell
ist es **immer** wichtig, dass jeder Datensatz durch eine eindeutige
Fallnummer zu identifizieren ist. Da eine solche in den eingelesenen
Daten jedoch nicht enthalten ist, fügen wir selber eine Fallnummer
hinzu:

```{r}
npi$casenum <- 1:nrow(npi)
```

### Identifikation von fehlenden Werten

Das NPI besteht aus 40 Items. Aus dem *Codebuch* des NPI
Datensatzes[^codebuch] erfahren wir, dass Antworten auf die NPI Items
die Werte 1 und 2 annehmen können.  Die Antwort auf jedes Item des NPI
besteht aus einer „forced choice“ zwischen zwei Aussagen; eine davon
wird als Indikator für Narzissmus interpretiert. Item 1 besteht
beispielsweise aus den folgenden beiden Aussagen:

[^codebuch]: Dieses wird gemeinsam mit den Daten des „Open Source
Psychometrics Project“
[https://openpsychometrics.org/_rawdata](https://openpsychometrics.org/_rawdata)
runtergeladen.

> 1. I have a natural talent for influencing people.
> 2. I am not good at influencing people.

Die Wahl von Aussage 1 wird mit 1 kodiert, die Wahl von Aussage 2 mit 2.
Nachgeschaltet wird folgende Umkodierung vorgenommen, die die
Item-Scores berechnet: Wird die „narzisstische Aussage“ ausgewählt (hier
Aussage 1: „I have a natural talent for influencing people.“), wird das
Item mit 1 bepunktet. Wird die Aussage gewählt, die nicht für Narzissmus
steht (hier Aussage 2: „I am not good at influencing people.“), wird
eine 0 vergeben. Wie wir zu Beginn dieses Kapitels gelernt haben, können
wir Item 1 wie folgt bepunkten:

```R
npi$Q1_score <- ifelse(npi$Q1 == 1, 1, 0)
```

**Aber Vorsicht: so würden wir einen Fehler machen**! Die Spalte
`npi$Q1` enthält nicht nur die Werte 1 und 2, sondern auch den Wert 0,
wie wir mit dem Befehl `table(npi$Q1)` prüfen können:


```{r}
table(npi$Q1)
```

Wie wir sehen, wurden die Antwortkategorien 0, 1 und 2 vergeben. Es
kommt sogar `r table(npi$Q1)[1]` Mal die Antwortkategorie 0 vor --
**obwohl Antworten nur die Werte 1 und 2 annehmen dürfen**. Wie kommt
das? Die Antwort ist: Bei der Bearbeitung des NPI-Fragebogens -- die im
Rahmen einer Online-Studie stattfand -- konnten Teilnehmer/innen Items
unbeantwortet lassen. Fehlende Werte wurden mit einer 0 kodiert. Mit
diesen fehlenden Werten müssen wir umgehen, bevor wir mit der
psychometrischen Auswertung starten können. 

Dafür wenden wir ein recht radikales Vorgehen an: Wir schließen einfach
alle Personen aus, bei denen mindestens eine Antwort fehlt. Folgende
Funktionen können uns dabei helfen:

- `complete.cases`: Gibt für einen `data.frame` aus, welche Zeilen 
  **keine** fehlenden Werte enthalten (als logischen Vektor)
- `na.omit`: Gibt von einem `data.frame` nur die Zeilen ohne fehlende 
  Werte aus

Der erste Schritt ist, alle fehlenden Werte -- die derzeit mit 0 kodiert
sind -- in `NA` umzuwandeln. Nur `NA` wird von `R` tatsächlich als
fehlend interpretiert; Konventionen, die Werte wie -99 oder 0 als
fehlend klassifizieren, kennt `R` nicht. 

Am liebsten würden wir im NPI-Datensatz alle Werte auf `NA` setzen, die
per 0 als fehlend klassifiziert wurden. Dafür könnten wir ein Vorgehen
verwenden, das wir in [Kapitel 2](#vektorAendern) für Vektoren
kennengelernt haben. Dieses Vorgehen funktioniert bei `data.frames`
tatsächlich gleichermaßen:[^fortgeschritten]

[^fortgeschritten]: Beachtet, dass hier ein Zugriff auf `data.frames`
mit eckigen Klammern stattfindet (siehe [Kapitel 
3.5](#fortgeschritten)). Der Befehl sieht recht harmlos aus, aber
tatsächlich steckt hier etwas mehr dahinter, als wir bislang behandelt
haben. Wir nehmen zunächst einmal einfach hin, dass die Umkodierung von
Werten in `data.frames` ebenso funktioniert wie bei Vektoren. Wie wir
schon bei Vektoren kennengelernt haben, sind viele Operationen in `R` so
allgemein, dass sie auf allen Daten eines Objekts stattfinden. 

```{r, eval = FALSE}
npi[npi == 0] <- NA
```

Dabei ergibt sich jedoch ein Problem: Fehlende Werte wurden im Datensatz
zwar mit 0 kodiert, jedoch existiert eine Spalte (`score`), die den Wert
0 aus zwei Gründen enthalten kann:

1. Der Wert fehlt.
2. Eine Person hat in keinem der 40 Items der narzisstischen Aussage 
   zugestimmt.

Der Gesamt-Testscore (`npi$score`) kann also wirklich den Wert 0
annehmen, wenn Teilnehmer/innen kein einziges Mal der narzisstischen
Aussage zugestimmt haben -- und dies kam tatsächlich 73 Mal vor. Würden
wir alle Personen ausschließen, die in irgendeiner Spalte den Wert 0
haben, würden wir zu viele Personen ausschließen. Wir würden sogar eine
Verzerrung in den Datensatz einfügen, da wir gezielt die Personen
ausschließen, die besonders wenig narzisstisch sind. Hier war es also
kein gutes Vorgehen, 0 als Kodierung für fehlende Werte zu verwenden.
Stattdessen wird oftmals ein Wert verwendet, der selbst nicht Teil des
legalen Wertebereichs ist -- idealerweise sollte der Wert in gar keiner
Spalte einer Datentabelle vorkommen können. Eine Konvention ist es, die
Zahl -99 zu verwenden, die dieses Kriterium oftmals erfüllt.

Um Personen mit fehlenden Werten zu identifizieren, erstellen wir
zunächst einen `data.frame`, der die Spalte `score` nicht enthält. Da
wir die Spalte aber nicht gänzlich verlieren wollen, speichern wir den
`data.frame` in einer neuen Variablen ab.

```{r}
# temp = temporäre Variable
temp <- subset(npi, select = -score)
```

Nun setzen wir in diesem temporären `data.frame` alle Nullen auf `NA`:

```{r}
temp[temp == 0] <- NA
```

Als Nächstes nutzen wir die Funktion `complete.cases`, um
herauszufinden, in welchen Zeilen von `temp` fehlende Werte vorliegen:

```{r}
is_complete <- complete.cases(temp)
head(is_complete, n = 10)
```

Die Funktion `complete.cases` gibt einen logischen Vektor der Länge
`nrow(temp)` zurück, der pro Zeile kodiert, ob irgendwo ein fehlender
Wert vorliegt. Also können wir wie folgt überprüfen, wie viele Fälle mit
fehlenden Werten es insgesamt gibt:

```{r}
sum(!is_complete)
```

Ebenfalls können wir nun aus dem ursprünglichen Datensatz `npi` nur die
vollständigen Fällen auswählen:

```{r}
npi_clean <- npi[is_complete, ]

nrow(npi_clean)
```

Mit dem Datensatz `npi_clean` können wir nun psychometrische
Berechnungen durchführen, da wir nur vollständige Datensätze ausgewählt
haben. Dabei ist unser nächstes Ziel, für alle 40 Items eine dichotome
Bepunktung durchzuführen. Wir wissen bereits, wie das funktioniert,
nämlich indem wir mit `ifelse` die Antworten auf jedes Item mit dem
Schlüssel abgleichen. Der Schlüssel für das NPI kodiert für jedes der 40
Items den Wert, der für Narzissmus steht. Dies wäre wie folgt möglich:

```R
# Hier kein legaler R-Code, nur exemplarisch:
npi_key <- c(1, 1, ..., 2) # 40 Schlüsselemente

npi$Q1_score <- ifelse(npi$Q1 == npi_key[1], 1, 0)

# ...

npi$Q40_score <- ifelse(npi$Q40 == npi_key[40], 1, 0)
```

Da wir nicht denselben Code -- mit leichten Abwandlungen -- 40 Mal
wiederholen wollen, werden wir in Kapitel 7 lernen, diese Umkodierungen
effizient  durchzuführen, also auf einmal für alle 40 Spalten. 


### Vergleiche mit `NA`

Die Funktion `complete.cases` gibt uns pro Zeile aus, ob darin Werte
fehlen. Es gibt einige weitere Funktionen, um das Vorliegen von
fehlenden Werten zu prüfen. 

Eine allgemein nützliche Funktion zum Betrachten von `data.frames` ist
die Funktion `summary`. Sie gibt uns wie folgt einen schnellen Überblick
über alle Spalten eines `data.frames`: 

```R
summary(npi)
# Ausgabe unterdrückt, da pro Spalte eine Tabelle ausgegeben wird
```

Neben einigen deskriptiven Statistiken gibt `summary` auch für jede
Spalte an, wie viele Werte darin fehlen. Für eine einzelne Spalte können
wir auch mit der Funktion `is.na` überprüfen, ob sie fehlende Werte
enthält:

```{r}
sum(is.na(temp$Q1))
sum(is.na(temp$Q40))
```

Die Funktion `is.na` prüft in einem Vektor, welche Werte `NA` sind und
gibt an den entsprechenden Positionen `TRUE` zurück, ansonsten `FALSE`.
**Wichtig**: Man **muss** `is.na` verwenden, um zu prüfen, ob Werte in
einem Vektor `NA` sind. Folgender „naiver“ Vergleich mit `NA` geht
schief:

```{r}
head(npi$Q1 == NA)
```

Ein logischer Vergleich mit `NA` ergibt immer `NA`, da beim fehlenden
Wert keine Aussage darüber gemacht werden kann, ob er einem anderen Wert
entspricht. Man kennt den fehlenden Wert zwar nicht, aber irgendeine
Ausprägung hat er in der Realität. 

Interessant ist auch der Umgang der UND- und ODER-Operationen mit
fehlenden Werten. Der Befehl `TRUE & NA` gibt `NA` aus. Denn je nachdem,
ob der fehlende Wert `TRUE` oder `FALSE` wäre, wäre das Ergebnis auch
entweder `TRUE` oder `FALSE`. Wir können in diesem Fall nicht
voraussagen, was das Ergebnis der UND-Operation wäre, da der fehlende
Wert unbekannt, aber kritisch für das Ergebnis ist. Anders sieht es bei
dem Befehl `TRUE | NA` aus. Dieser ergibt `TRUE`, da auf jeden Fall eine
Bedingung erfüllt ist und nur eine Bedingung erfüllt sein muss, damit
die ODER-Bedingung `TRUE` ergibt. Mit diesen Erklärungen im Hinterkopf
können wir auch nachvollziehen, was passiert, wenn wir `FALSE` mit `NA`
per UND und ODER verknüpfen: `FALSE | NA` ergibt `NA`, `FALSE & NA`
ergibt `FALSE`.


## Fragen zum vertiefenden Verständnis

1. Gegeben ist der Antwortvektor `c(1, 2, 2, 1, 4, 5, 2, 2, 2, 3)` und
   der Schlüssel `2`. Wie kann ich die Item-Schwierigkeit ohne Anwendung
   der Funktion `ifelse()` bestimmen? Was ist die Item-Schwierigkeit?

```{r, eval = FALSE, echo = FALSE}
mean(c(1, 2, 2, 1, 4, 5, 2, 2, 2, 3) == 2)
```

3. Gegeben ist der Antwortvektor `c(2, 3, 2, 4, 5, 6, 2, 3)`, der die
   Antworten auf das Item eines Persönlichkeitsinventars enthält. Die
   Antworten wurden auf einer Likertskala gegeben, die zwischen 1 und 6
   kodiert war.  Da das Item negativ gepolt ist, müssen die Antworten
   vor der Analyse invertiert werden. Was ist der Mittelwert der
   umgepolten Antworten (d.h. die Item-Schwierigkeit)?

```{r, eval = FALSE, echo = FALSE}
mean(c(2, 3, 2, 4, 5, 6, 2, 3) * (-1) + 7)
```
